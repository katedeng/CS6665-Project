{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2023springcourses\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCS6665\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcs6665 course project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirname, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(base_dir):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, filename))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "base_dir = r\"D:\\2023springcourses\\CS6665\\cs6665 course project\\data\"\n",
    "for dirname, _, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##import libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from scipy import stats\n",
    "#import jpx_tokyo_market_prediction\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understand how to calculate scores and deepen your understanding of Rank ##\n",
    "https://www.kaggle.com/code/smeitoma/jpx-competition-metric-definition\n",
    "https://www.kaggle.com/code/chumajin/easy-to-understand-the-competition?scriptVersionId=94143164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look for the stock_prices.csv in train file\n",
    "stock_prices=pd.read_csv(f\"{base_dir}/train_files\"+'/stock_prices.csv')\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_prices[\"Date\"] = pd.to_datetime(stock_prices[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look for only one stock,eg.1301\n",
    "tmpdf = stock_prices[stock_prices[\"SecuritiesCode\"]==1301].reset_index(drop=True)\n",
    "tmpdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # calculate TARGET (change rate of Close on the next day and the next day) by yourself.\n",
    "tmpdf[\"Close_shift1\"] = tmpdf[\"Close\"].shift(-1)\n",
    "tmpdf[\"Close_shift2\"] = tmpdf[\"Close\"].shift(-2)\n",
    "\n",
    "tmpdf[\"rate\"] = (tmpdf[\"Close_shift2\"] - tmpdf[\"Close_shift1\"]) / tmpdf[\"Close_shift1\"]\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Target and the rate calculated match. (so I will use the Target that is calculated from now on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank calculation. ##\n",
    "First, let's take a look at only one day. * Please note that not all 2000 stocks have data depending on the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpdf2 = stock_prices[stock_prices[\"Date\"]==\"2021-12-03\"].reset_index(drop=True)\n",
    "tmpdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank in descending order of Target. I do sort it for understanding. Rank is tied to 0-1999, so don't forget -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpdf2[\"rank\"] = tmpdf2[\"Target\"].rank(ascending=False,method=\"first\") -1 \n",
    "tmpdf2 = tmpdf2.sort_values(\"rank\").reset_index(drop=True)\n",
    "tmpdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of daily spread return of this day ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpdf2_top200 = tmpdf2.iloc[:200,:]\n",
    "weights = np.linspace(start=2, stop=1, num=200)\n",
    "tmpdf2_top200[\"weights\"] = weights\n",
    "tmpdf2_top200[\"calc_weights\"] = tmpdf2_top200[\"Target\"] * tmpdf2_top200[\"weights\"]\n",
    "Sup = tmpdf2_top200[\"calc_weights\"].sum()/np.mean(weights)\n",
    "Sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpdf2_bottom200 = tmpdf2.iloc[-200:,:]\n",
    "tmpdf2_bottom200 = tmpdf2_bottom200.sort_values(\"rank\",ascending = False).reset_index(drop=True)\n",
    "tmpdf2_bottom200[\"weights\"] = weights\n",
    "tmpdf2_bottom200[\"calc_weights\"] = tmpdf2_bottom200[\"Target\"] * tmpdf2_bottom200[\"weights\"]\n",
    "Sdown = tmpdf2_bottom200[\"calc_weights\"].sum()/np.mean(weights)\n",
    "Sdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate daily spread return\n",
    "daily_spread_return = Sup - Sdown\n",
    "daily_spread_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): predicted results\n",
    "        portfolio_size (int): # of equities to buy/sell\n",
    "        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "    Returns:\n",
    "        (float): sharpe ratio\n",
    "    \"\"\"\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): predicted results\n",
    "            portfolio_size (int): # of equities to buy/sell\n",
    "            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "        Returns:\n",
    "            (float): spread return\n",
    "        \"\"\"\n",
    "        assert df['Rank'].min() == 0\n",
    "        assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate which days have 2000 stocks\n",
    "idcount = stock_prices.groupby(\"Date\")[\"SecuritiesCode\"].count().reset_index()\n",
    "idcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(idcount[\"Date\"],idcount[\"SecuritiesCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idcount.loc[idcount[\"SecuritiesCode\"]==2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_prices2 = stock_prices.loc[stock_prices[\"Date\"]>= \"2021-01-01\"].reset_index(drop=True)\n",
    "stock_prices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_prices2[\"Rank\"] = stock_prices2.groupby(\"Date\")[\"Target\"].rank(ascending=False,method=\"first\") -1 \n",
    "stock_prices2[\"Rank\"] =stock_prices2[\"Rank\"].astype(\"int\")\n",
    "stock_prices2[\"Rank\"].min()\n",
    "score = calc_spread_return_sharpe(stock_prices2, portfolio_size= 200, toprank_weight_ratio= 2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "supplemental_stock_prices=pd.read_csv(f\"{base_dir}/supplemental_files\"+'/stock_prices.csv')\n",
    "supplemental_stock_prices[\"Rank\"] = supplemental_stock_prices.groupby(\"Date\")[\"Target\"].rank(ascending=False,method=\"first\") -1\n",
    "idcount1 = supplemental_stock_prices.groupby(\"Date\")[\"SecuritiesCode\"].count().reset_index()\n",
    "idcount1.loc[idcount1[\"SecuritiesCode\"]==2000,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finday = supplemental_stock_prices[supplemental_stock_prices[\"Date\"]==\"2022-04-22\"].reset_index(drop=True)\n",
    "finday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finday[finday[\"Rank\"]==finday[\"Rank\"].iloc[0]]\n",
    "#finday[\"Rank\"] = finday[\"Rank\"].astype(\"int\")\n",
    "findaydict = dict(zip(finday[\"SecuritiesCode\"],finday[\"Rank\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample_prediction[\"Rank\"]  = sample_prediction[\"SecuritiesCode\"].map(findaydict)\n",
    "#sample_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices=pd.read_csv(f\"{base_dir}/train_files\"+'/stock_prices.csv')\n",
    "secondary_stock_prices=pd.read_csv(f\"{base_dir}/train_files\"+'/secondary_stock_prices.csv')\n",
    "supplemental_stock_prices=pd.read_csv(f\"{base_dir}/supplemental_files\"+'/stock_prices.csv')\n",
    "supplemental_secondary_stock_prices=pd.read_csv(f\"{base_dir}/supplemental_files\"+'/secondary_stock_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_prices.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secondary_stock_prices.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "supplemental_stock_prices.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "supplemental_secondary_stock_prices.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join the datas in the train file and supplemental files\n",
    "stock_prices = stock_prices.append(secondary_stock_prices)\n",
    "stock_prices = stock_prices.append(supplemental_stock_prices)\n",
    "stock_prices= stock_prices.append(supplemental_secondary_stock_prices)\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime type\n",
    "stock_prices['Date'] = pd.to_datetime(stock_prices['Date'])\n",
    "\n",
    "# Get the data in the year 2021 \n",
    "stock_prices2021 = stock_prices[stock_prices['Date'] > pd.to_datetime('2021-01-01')]\n",
    "\n",
    "stock_prices2021=stock_prices2021.drop(columns=['RowId','Date','SecuritiesCode','ExpectedDividend','SupervisionFlag'])\n",
    "\n",
    "stock_prices2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlations about features\n",
    "sns.heatmap(stock_prices2021.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(data = stock_prices2021, vars = ['Open', 'High', 'Low','Close','Volume','Target'])\n",
    "g.map_offdiag(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. from the graphs we can see the features(Open,High,Low,Close) are postive correlation.\n",
    "2. The relationshio between the features(Open,High,Low,Close,Volume) and target presents a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. from the stock_prices.cvs, we can know that the values of ExpectedDividend are nan, so we will set  the value to zero.\n",
    "2. the values of SupervisionFlag is binary, so we change them to int.\n",
    "3. if some values of target are missing, we will set 0 to them.\n",
    "4.we will choose the features:'Open', 'High', 'Low', 'Close'. becase In investing and trading, Z-scores are measures of an instrument's variability and can be used by traders to help determine volatility. so we will use zscore to scale the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    data['ExpectedDividend'] = data['ExpectedDividend'].fillna(0)\n",
    "    data[\"SupervisionFlag\"] = data[\"SupervisionFlag\"].astype(int)\n",
    "    data['Target'] = data['Target'].fillna(0)\n",
    "    \n",
    "    cols = ['Open', 'High', 'Low', 'Close']\n",
    "    data.loc[:,cols] = data.loc[:,cols].ffill()\n",
    "    data.loc[:,cols] = data.loc[:,cols].bfill()\n",
    "\n",
    "    \n",
    "\n",
    "    data['Open'] = stats.zscore(data['Open'])\n",
    "    data['High'] = stats.zscore(data['High'])\n",
    "    data['Low'] = stats.zscore(data['Low'])\n",
    "    data['Close'] = stats.zscore(data['Close'])\n",
    "   \n",
    "    \n",
    "    data = data.drop(['RowId', 'Date'], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featuring_2(data):\n",
    "    data['ExpectedDividend'] = data['ExpectedDividend'].fillna(0)\n",
    "    data[\"SupervisionFlag\"] = data[\"SupervisionFlag\"].astype(int)\n",
    "    \n",
    "    cols = ['Open', 'High', 'Low', 'Close']\n",
    "    data.loc[:,cols] = data.loc[:,cols].ffill()\n",
    "    data.loc[:,cols] = data.loc[:,cols].bfill()\n",
    "\n",
    "    \n",
    "    \n",
    "    data['Open'] = stats.zscore(data['Open'])\n",
    "    data['High'] = stats.zscore(data['High'])\n",
    "    data['Low'] = stats.zscore(data['Low'])\n",
    "    data['Close'] = stats.zscore(data['Close'])\n",
    "   \n",
    "    \n",
    "    data = data.drop(['RowId', 'Date','Target'], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=feature_engineering(stock_prices)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1=df.drop(['Target'],axis=1)\n",
    "df_1.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create models ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_X=df.drop(['Target'], axis=1)\n",
    "df_Y=df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X,df_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1 : Linear regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of the LinearRegression class\n",
    "model_reg = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model_reg.predict(X_test)\n",
    "\n",
    "# print the parameters\n",
    "print(model_reg.coef_) \n",
    "print(model_reg.intercept_) \n",
    "print(model_reg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(math.sqrt(mean_squared_error(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(model_reg, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate the mean and standard deviation of the training scores and testing scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_mean, label='Train')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.plot(train_sizes, test_mean, label='Test')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)\n",
    "plt.xlabel('Number of training sizes')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spread_return_per_day(df, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    assert df['Rank'].min() == 0\n",
    "    assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    return purchase - short\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    buf = df.groupby('Date').apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio#, buf\n",
    "\n",
    "def add_rank(df):\n",
    "    df[\"Rank\"] = df.groupby(\"Date\")[\"Target\"].rank(ascending=False, method=\"first\") - 1 \n",
    "    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n",
    "    return df\n",
    "\n",
    "def fill_nan_inf(df):\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    return df\n",
    "\n",
    "def check_score(df,preds,Securities_filter=[]):\n",
    "    tmp_preds=df[['Date','SecuritiesCode']].copy()\n",
    "    tmp_preds['Target']=preds\n",
    "    \n",
    "    #Rank Filter. Calculate median for this date and assign this value to the list of Securities to filter.\n",
    "    tmp_preds['target_mean']=tmp_preds.groupby(\"Date\")[\"Target\"].transform('median')\n",
    "    tmp_preds.loc[tmp_preds['SecuritiesCode'].isin(Securities_filter),'Target']=tmp_preds['target_mean']\n",
    "    \n",
    "    tmp_preds = add_rank(tmp_preds)\n",
    "    df['Rank']=tmp_preds['Rank']\n",
    "    score=round(calc_spread_return_sharpe(df, portfolio_size= 200, toprank_weight_ratio= 2),5)\n",
    "    score_mean=round(df.groupby('Date').apply(calc_spread_return_per_day, 200, 2).mean(),5)\n",
    "    score_std=round(df.groupby('Date').apply(calc_spread_return_per_day, 200, 2).std(),5)\n",
    "    print(f'Competition_Score:{score}, rank_score_mean:{score_mean}, rank_score_std:{score_std}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_score(test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
